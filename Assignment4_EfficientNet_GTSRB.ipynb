{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "991b582c",
      "metadata": {
        "id": "991b582c"
      },
      "source": [
        "# German Traffic Sign Detection with EfficientNet_B0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8346e461",
      "metadata": {},
      "source": [
        "## Team members\n",
        "Ketiyape Samarasekara Kasunki Samarasekara (2304486) \\\n",
        "Subramaniyamge Ruwani Rangika Weerasinghe (2305168)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NVkUSdnA2Rw3",
      "metadata": {
        "id": "NVkUSdnA2Rw3"
      },
      "source": [
        "# STEP 1: Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd2f386b",
      "metadata": {
        "id": "cd2f386b"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import GTSRB\n",
        "from torchvision.models import efficientnet_b0\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ekp4ApVW2VF-",
      "metadata": {
        "id": "Ekp4ApVW2VF-"
      },
      "source": [
        "# STEP 2: Load the GTSRB Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea4d9c3a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea4d9c3a",
        "outputId": "620a508b-0b5a-4c97-acae-141b13cc363d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of classes: 43\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Data transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Load GTSRB dataset\n",
        "train_set = GTSRB(root='./data', split='train', transform=transform, download=True)\n",
        "test_set = GTSRB(root='./data', split='test', transform=transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n",
        "\n",
        "# Determine number of classes from the dataset\n",
        "import numpy as np\n",
        "\n",
        "# Convert labels into a NumPy array and get unique class count\n",
        "all_labels = [label for _, label in train_set]\n",
        "num_classes = len(np.unique(all_labels))\n",
        "\n",
        "print(\"Number of classes:\", num_classes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Io3fkS8Q2bCo",
      "metadata": {
        "id": "Io3fkS8Q2bCo"
      },
      "source": [
        "# STEP 3: Load Pretrained Model (EfficientNet_B0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49c0beaf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49c0beaf",
        "outputId": "64bc2e5f-8b74-476c-e9a6-e26082307be5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy of pre-trained model without any fine tuning: 1.88%\n"
          ]
        }
      ],
      "source": [
        "# Load EfficientNet_B0 pre-trained model\n",
        "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "weights = EfficientNet_B0_Weights.DEFAULT  # or .IMAGENET1K_V1 if preferred\n",
        "model = efficientnet_b0(weights=weights)\n",
        "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Test accuracy without fine-tuning\n",
        "acc_pretrain = evaluate(model, test_loader)\n",
        "print(\"Test Accuracy of pre-trained model without any fine tuning: {:.2f}%\".format(acc_pretrain))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67qbUUkz2iM1",
      "metadata": {
        "id": "67qbUUkz2iM1"
      },
      "source": [
        "# STEP 4: Train the Model (Fine-Tuning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7058c3f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7058c3f7",
        "outputId": "bc92f657-a129-4402-8ed5-7aba54a075e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1 | loss 0.9075\n",
            "Test accuracy of pre-trained model after fine-tuning and before quantization : 96.53%\n"
          ]
        }
      ],
      "source": [
        "# Fine-tune the model\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# Train for 1 epoch\n",
        "model.train()\n",
        "for epoch in range(1):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/1 | loss {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "acc_finetune = evaluate(model, test_loader)\n",
        "print(\"Test accuracy of pre-trained model after fine-tuning and before quantization : {:.2f}%\".format(acc_finetune))\n",
        "\n",
        "# Save model temporarily\n",
        "torch.save(model.state_dict(), \"efficientnet_b0_gtsrb.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qZO0Dwr32tHr",
      "metadata": {
        "id": "qZO0Dwr32tHr"
      },
      "source": [
        "# STEP 5: Quantize the Model (INT8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PlNI5zq82wei",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlNI5zq82wei",
        "outputId": "847a4473-84a2-4e19-de08-f98ae99a4c81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model size before quantization: 16.55 MB\n",
            "Model size after quantization: 16.38 MB\n",
            "Memory saving: 0.99%\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Quantization\n",
        "model.cpu()\n",
        "model.eval()\n",
        "\n",
        "quantized_model = torch.quantization.quantize_dynamic(\n",
        "    model, {torch.nn.Linear}, dtype=torch.qint8\n",
        ")\n",
        "\n",
        "# Save both models to compare sizes\n",
        "torch.save(model.state_dict(), \"efficientnet_b0_fp32.pth\")\n",
        "torch.save(quantized_model.state_dict(), \"efficientnet_b0_int8.pth\")\n",
        "\n",
        "# Model size comparison\n",
        "import os\n",
        "fp32_size = os.path.getsize(\"efficientnet_b0_fp32.pth\") / 1e6\n",
        "int8_size = os.path.getsize(\"efficientnet_b0_int8.pth\") / 1e6\n",
        "print(f\"Model size before quantization: {fp32_size:.2f} MB\")\n",
        "print(f\"Model size after quantization: {int8_size:.2f} MB\")\n",
        "print(f\"Memory saving: {(fp32_size - int8_size) / fp32_size * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FAqOOqRZ20iy",
      "metadata": {
        "id": "FAqOOqRZ20iy"
      },
      "source": [
        "# STEP 6: Accuracy After Quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uSmwK2lY24pP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSmwK2lY24pP",
        "outputId": "f1337907-3c2e-449d-c903-92a8ea9676f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy before quantization: 96.53%\n",
            "Test accuracy after quantization: 96.52%\n",
            "Accuracy drop after quantization: 0.02%\n"
          ]
        }
      ],
      "source": [
        "# Quantize the model\n",
        "model_int8 = copy.deepcopy(model).to('cpu')  # move to CPU for quantization\n",
        "model_int8.eval()\n",
        "\n",
        "quantized_model = torch.quantization.quantize_dynamic(\n",
        "    model_int8, {nn.Linear}, dtype=torch.qint8\n",
        ")\n",
        "\n",
        "# Define evaluate function\n",
        "def evaluate(model, loader, device=torch.device(\"cpu\")):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move original model to the appropriate device\n",
        "model.to(device)\n",
        "\n",
        "# Evaluate original and quantized models\n",
        "acc_original = evaluate(model, test_loader, device)\n",
        "acc_quant = evaluate(quantized_model, test_loader, device=torch.device(\"cpu\"))\n",
        "\n",
        "# Print results\n",
        "print(f\"Test accuracy before quantization: {acc_original:.2f}%\")\n",
        "print(f\"Test accuracy after quantization: {acc_quant:.2f}%\")\n",
        "print(f\"Accuracy drop after quantization: {acc_original - acc_quant:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GsU3qYay28UO",
      "metadata": {
        "id": "GsU3qYay28UO"
      },
      "source": [
        "# STEP 7: Latency Benchmarking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jYYgvbFw3Fmf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYYgvbFw3Fmf",
        "outputId": "e4f6be8d-8cc5-4131-a33c-1ab9c82155b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average inference latency (ms) before quantization: 4842.15\n",
            "Average inference latency (ms) after quantization: 4902.52\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def benchmark_latency(model, loader, n=10):\n",
        "    model.eval()\n",
        "    timings = []\n",
        "    inputs_list = []\n",
        "    for i, (inputs, _) in enumerate(loader):\n",
        "        inputs_list.append(inputs)\n",
        "        if len(inputs_list) == n:\n",
        "            break\n",
        "    for inputs in inputs_list:\n",
        "        start = time.time()\n",
        "        with torch.no_grad():\n",
        "            model(inputs)\n",
        "        end = time.time()\n",
        "        timings.append((end - start) * 1000)  # convert to ms\n",
        "    return np.mean(timings)\n",
        "\n",
        "latency_before = benchmark_latency(model.to(\"cpu\"), test_loader)\n",
        "latency_after = benchmark_latency(quantized_model, test_loader)\n",
        "\n",
        "print(\"Average inference latency (ms) before quantization: {:.2f}\".format(latency_before))\n",
        "print(\"Average inference latency (ms) after quantization: {:.2f}\".format(latency_after))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
